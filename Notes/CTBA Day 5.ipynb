{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83dabca",
   "metadata": {},
   "source": [
    "**Data Acquisition**\n",
    "\n",
    "Process of gathering information from a variety of sources to store, process, and analyze it\n",
    "\n",
    "*Process*\n",
    "- Sensing with sensors or instruments to measure physical or digital data\n",
    "- Signal Conditioning; refinement of raw data, such as amplifying, filtering, or even digitizing\n",
    "- Converting analog data to digital data\n",
    "- Logging, storing, analyzing, processing, and visualizing to extract insights\n",
    "- One of the challenges is the many types of data that might be collected; numerical, textual, multimodal\n",
    "    - Data may be unstructured, requiring manual cleaning (or unsupervised learning) to prepare \n",
    "\n",
    "*Retrieval Methods*\n",
    "- File-based; structured .csv, .xlsx, .json file extensions\n",
    "- Database; SQL and NoSQL query commands\n",
    "- APIs; Structured, programmatic\n",
    "- Web scraping; Automated extraction from websites\n",
    "- Data marketplaces; Paid access to certain data \n",
    "\n",
    "*Challenges*\n",
    "- Data quality;\n",
    "    - Is the data accurate and complete?\n",
    "    - Is the data biased? \n",
    "- Data volume - Storing, analyzing, and computing a massive amount of data\n",
    "- Data variety - Related data sourced from a variety of sources and modalities\n",
    "- Integration - Getting data from different siloes \n",
    "- Costs - Sensors, equipment, software, personnel\n",
    "- Scalability - Marginal cost of storing additional data \n",
    "- Governance - Who owns data? Who manages the lifecycle and stores it?\n",
    "\n",
    "**API and Web Scraping**\n",
    "- API; standardized interface from which to collect data, which allows developers to directly access a structured dataset in a machine-readable format\n",
    "- Web scraping; Technique for extracting information from HTML/human readable formats. Fragile, requires parsing, and often manual cleaning\n",
    "    - All websites are different and require custom work\n",
    "    - Websites are constantly changing, and so web scraping apps must be constantly updated as well\n",
    "    - Fragility, manual work, unstructured, etc.\n",
    "\n",
    "*Beautiful Soup*\n",
    "- Library for HTML and XML parsing; tackles poorly structured HTML sites\n",
    "- Add Selenium to handle dynamic, JS pages\n",
    "- Practical applications;\n",
    "    - Competitor analysis\n",
    "    - Sentiment analysis\n",
    "    - Market research\n",
    "    - Price monitoring\n",
    "    - Content aggregation\n",
    "- Can be used with Pandas, lxml, and Selenium\n",
    "\n",
    "*API*\n",
    "- Send request; receive structured response\n",
    "- APIs can be structured in different ways; many are REST, but there are other options\n",
    "    - Some require authentication; private APIs might be locked behind an account or paywall \n",
    "- Python has specialized libraries for different kinds of APIs; requests is straightforward for most\n",
    "- API Key is a unique code granted when you sign up for an API; Controls access and tracks usage\n",
    "    - Keep private\n",
    "\n",
    "*Formatting*\n",
    "- JSON; Organized as key-value pairs\n",
    "\n",
    "**Ensuring High-Quality Data**\n",
    "- Curate sources and clean data\n",
    "- Audit for bias\n",
    "- Balance content to remove bias\n",
    "- Validate outputs by checking for hallucinations\n",
    "- Document process with transparency"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
