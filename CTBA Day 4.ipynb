{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc63e5f",
   "metadata": {},
   "source": [
    "**AI Ethics**\n",
    "- Ethics are not abstract; They are encoded into the architecture and operations of an AI system\n",
    "- Who is at fault when an AI system fails?\n",
    "- AI systems should:\n",
    "    - Provide individuals autonomy and work on consent\n",
    "    - Avoid bias\n",
    "    - Promote human well-being\n",
    "    - Avoid intentional or unintentional human harm\n",
    "    - Be transparent and understandable to all who interact with it\n",
    "\n",
    "*Business Considerations*\n",
    "- Tension in the business decision between granting individuals autonomy to opt-out vs. collecting valuable data\n",
    "- Responsibility is ensuring the principles above; profit motives may differ from responsibility\n",
    "\n",
    "*Cybersecurity*\n",
    "- How to secure a network across multiple domains\n",
    "    - Accountability for security of the network or parts of the network; Tracing malicious actors or issues in the algorithm\n",
    "    - Keeping data and systems accurate and protecting them from tampering\n",
    "    - Keeping confidential data safe from unauthorized access\n",
    "    - Making sure systems are resilient and responsive even when under stress\n",
    "- This is an ethical responsibility on the part of organizations and leaders who hold user data\n",
    "    - The challenge is that AI systems and algorithms can be, by their very nature, fast amplifiers of maliciousness\n",
    "\n",
    "*Ethical Challenges*\n",
    "- Echo chambers and amplification; Algorithms, especially on social media, make it extremely easy to end up in an echo chamber\n",
    "- Deepfakes and other misinformation distort reality, especially for low-information or shallow viewers\n",
    "\n",
    "*Bias*\n",
    "- Existing bias (separations from reality) in training data or measurement is encoded into the AI model\n",
    "    - Can be mitigated by intentionally including diverse data in the training set\n",
    "- Bias can be introduced by flaws in the algorithm or unintential biases from the developers\n",
    "\n",
    "*AI War*\n",
    "- AI can be used on both sides of cyberwarfare\n",
    "    - Automated and more effective attacking strategies vs more responsive defensive strategies\n",
    "    - Data poisoning to reduce AI effectiveness\n",
    "    - Breach vulnerability in defensive AI - access control and version control\n",
    "    - Fraud empowered by sophisticated phishing against both humans and computer systems\n",
    "    - Military: Autonomous logistics systems, drone and missle technologies, and sophisticated/untraceable cyberattacks\n",
    "- Digital platforms are vulnerable and struggle to respond to threats at scale and speed\n",
    "- Explainable AI with user-friendly interface = XAI \n",
    "\n",
    "*Considerations*\n",
    "- Involve all stakeholders (especially users) early and identify blind spots\n",
    "- Make sure that models are interpretable, especially when the stakes are higher\n",
    "- Ensure than human reviewers remain a part of critical decision making; don't replace human intuition entirely\n",
    "- Systematically and regularly audit the system's impact, including on indirectly affected demographics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
