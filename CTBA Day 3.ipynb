{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647a8a5a",
   "metadata": {},
   "source": [
    "**Multimodal Generative AI**\n",
    "- Gen AI is not predictive; it infers data (creates content) based on learned patterns from training data.\n",
    "    - Conversational (ChatGPT, Perplexity)\n",
    "    - Coding (Copilot)\n",
    "    - Images (DALL-E)\n",
    "\n",
    "- GenAI is a type of deep learning ML algorithm (subset of ML)\n",
    "    - ML algorithm based on deep neural networks which result in generative output\n",
    "    - Simulation of the human brain\n",
    "\n",
    "- GenAI is between Narrow AI (AI tool for a specific task) and AGI\n",
    "    - GenAI is a large foundation model that can adapt to various tasks; has not reached human-level intelligence yet \n",
    "\n",
    "- LM and LLM\n",
    "    - LMs are AI that generate new textual content by predicting future words \n",
    "    - LLMs are LMs trained on billions of parameters, which has enabled advanced capabilities\n",
    "    - MLLM (multimodal) are LLMs which can process and produce media in different modes; a step towards AGI\n",
    "    - These are having massive effects on a number of industries\n",
    "\n",
    "*Game Theory*\n",
    "- Systems learn best when there is some form of competition and resolution\n",
    "- Generative Adversarial Network (GAN); a generator competes against a discriminator - the generator wants to trick the discriminator into labeling generated data as real data\n",
    "- Process:\n",
    "    - Gathering large amounts of data in desired modes\n",
    "    - Training to iteratively teach the model patterns in the data\n",
    "    - Fine-tuning adapts the model to a specific task or domain\n",
    "\n",
    "*Chatbots*\n",
    "- Early chatbots were not flexible; they had a set of specific responses to specific prompts\n",
    "- Pattern recognition from labeled text (a form of ML) allows adaptive chatbots which can analyze inputs\n",
    "- Neural networks and NLP allow chatbots to increase input understanding and generate more dynamic outputs\n",
    "    - Contextual awareness\n",
    "\n",
    "*Transformers*\n",
    "- A transformer model (GPT) processes text in a way which weights words and pays more attention to certain inputs - through tokenization\n",
    "    - GPT can ignore and discriminate against unimportant inputs regardless of order\n",
    "    - This enables context\n",
    "\n",
    "*GPU*\n",
    "- Based on the power of a GPU; GPUs are better at parallel mathmatical performances involving vectors and matrices than CPUs\n",
    "    - Efficient GPUs allow running machine learning on smaller devices\n",
    "    - Open-source libraries which collaborate with organizations\n",
    "\n",
    "*GenOS*\n",
    "- Generative Open-Source Index which tracks gen AI projects and ranks them based on various factors\n",
    "- GPUs provide the physical infrastructure, GenOS provides the organization and delivery model\n",
    "\n",
    "*Training*\n",
    "- Supervised learning: Providing patterns from a labeled dataset\n",
    "- Unsupervised learning: Predicting words and comparing to correct outputs to adjust weights in the neural network\n",
    "- Often a cheap combination is used; a model is pre-trained on unsupervised large datasets, then fine-tuned with supervised learning\n",
    "- Reinforcement Learning with Human Feedback (RLHF)\n",
    "    - Human prferences guide the model's responses to align the model with our values and needs\n",
    "\n",
    "*Cross-Modal Embeddings*\n",
    "- Example; Connecting text to images; 'dog' points to a picture of a dog\n",
    "    - Allows image retrieval, captioning, etc.\n",
    "\n",
    "*Use of LLMs*\n",
    "- Much more flexible than rule-based models\n",
    "- Can handle and understand a variety of language and unstructured input - more generalized to global dialects - ignores errors and emojis, etc.\n",
    "    - Flexibility\n",
    "    - Generalization\n",
    "    - Learning method (unsupervised vs time-consuming)\n",
    "    - Robustness to Noise\n",
    "\n",
    "**Prompting** \n",
    "- Users use prompt engineering to leverave RLHF to align LLM outputs with their needs\n",
    "- Analogous to 'driving' the LLM - requires that the engine (GPU) and steering system (RLHF) work, but the final fine-tuning for output generation\n",
    "- The quality of the prompt is very important and can massively change the output \n",
    "- Art and science of providing quality prompts to the LLM to encourage helpful behavior\n",
    "- ChatGPT has been fine-tuned with RLHF; Humans have guided the model by rewarding helpful responses and discouraging unhelpful ones\n",
    "\n",
    "*Strategy*\n",
    "- Chain of Thought; encouraging a conclusion by asking the LLM to generate step-by-step reasoning\n",
    "- Few-Shot Input; providing examples for the model to base output on \n",
    "- Instructional; given roles or instructions, do x\n",
    "\n",
    "*Operations*\n",
    "- Iterate input based on output\n",
    "- Provide increasingly specific and helpful inputs\n",
    "    - Format\n",
    "    - Scope\n",
    "    - Style\n",
    "    - Ask for explicit uncertainty\n",
    "    - Ask for step-by-step\n",
    "- Allow the model to be wrong and to declare that\n",
    "- Split task into subtasks\n",
    "- Verify all information given\n",
    "- Reduce hallucinations\n",
    "    - Include instructions to not hallucinate\n",
    "    - Restrict output\n",
    "    - Add chain of thought style instructions\n",
    "    - Repeat instructions multiple times\n",
    "    - Position most important instructions towards the end (latency effect)\n",
    "- Spotting hallucinations\n",
    "    - Too specific or factual without a reference/source\n",
    "    - Fake sources/references\n",
    "    - Contradictions and inconsistencies\n",
    "    - Overconfidence when uncertain\n",
    "    - Lack of common sense \n",
    "- Math\n",
    "    - LLMs don't have internal logic; they just imitate math learned from outside sources\n",
    "    - Higher complexity means more potential for errors\n",
    "    - LLMs can't internally verify their answers\n",
    "\n",
    "**Future**\n",
    "- Combining rules with genAI\n",
    "- Increased fine-tuning per industry\n",
    "- Regulation and ethics\n",
    "- Open collaboration and shared data, benchmarks, and partnerships\n",
    "\n",
    "**Git and Github**\n",
    "- Git is a decentralized version control system for tracking file changes\n",
    "    - Tracks who made changes, when they were made, and what they were\n",
    "    - Best for text files (scripts, etc.)\n",
    "    - Accessed through terminal; git command\n",
    "    - GitHub is a website which receives git pushes\n",
    "- In VSCode; Source control tab on the left connects to GitHub\n",
    "- Nomenclature \n",
    "    - Repository; Where code lives\n",
    "    - Commit; A saved snapshot of code\n",
    "    - Branch; Independent line of development\n",
    "    - Merge; Bringing changes from a branch into another\n",
    "    - Pull Request (PR); Proposing changes for review\n",
    "    - Close; Downloading copy of repository to local machine\n",
    "    - Push; Sending local changes to GitHub (syncing)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
